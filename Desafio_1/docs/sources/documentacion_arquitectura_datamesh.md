# Arquitectura Data Mesh - Documento de DiseÃ±o

**Cliente:** Orbidi  
**Fecha:** Diciembre 2024  
**Autor:** AndrÃ©s R. Sotelo
**VersiÃ³n:** 2.0

---

## 1. Resumen Ejecutivo

Este documento presenta el diseÃ±o de una plataforma de datos moderna basada en el paradigma **Data Mesh** con **arquitectura Medallion** (Bronze/Silver/Gold) para un cliente de Orbidi. La soluciÃ³n integra mÃºltiples fuentes de datos heterogÃ©neas y habilita capacidades de Business Intelligence y Machine Learning, cumpliendo con los requisitos de:

- Hosting en **Google Cloud Platform**
- PriorizaciÃ³n de tecnologÃ­as **open-source**
- Enfoque fuerte en **GitOps y DataOps**
- Arquitectura **Data Mesh** con gobernanza federada
- **Dominio Maisons** como proyecto principal con datasets por capas

---

## 2. Contexto y ProblemÃ¡tica

### 2.1 SituaciÃ³n Actual del Cliente

El cliente opera con mÃºltiples sistemas desconectados:

| Tipo | Sistemas |
|------|----------|
| Bases de datos transaccionales | PostgreSQL, MySQL, MongoDB |
| Aplicaciones SaaS | SAP, Salesforce, SurveyMonkey |

### 2.2 Objetivos del Proyecto

1. **Consolidar** todas las fuentes de datos en una plataforma unificada
2. **Habilitar** tableros de BI para diversos departamentos
3. **Desarrollar** modelos de ML para recomendaciones y predicciones
4. **Establecer** gobernanza de datos federada
5. **Garantizar** extensibilidad para futuros productos de datos

---

## 3. Arquitectura Propuesta

### 3.1 VisiÃ³n General

La arquitectura se organiza en **6 capas** que siguen el flujo de datos desde las fuentes hasta el consumo:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA 6: CONSUMO                              â”‚
â”‚         (Superset, Vertex AI, Cloud Run APIs)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 CAPA 5: GOBERNANZA FEDERADA                     â”‚
â”‚    (IAM, DataHub, Great Expectations, Cloud Monitoring)         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              CAPA 4: DOMINIO MAISONS (BigQuery)                 â”‚
â”‚     ğŸ¥‰ Bronze â†’ ğŸ¥ˆ Silver â†’ ğŸ¥‡ Gold (por entidad)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               CAPA 3: PLATAFORMA CENTRAL                        â”‚
â”‚          (Airbyte, Cloud Composer, GCS Data Lake)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 CAPA 2: GitOps & DataOps                        â”‚
â”‚           (GitHub, Cloud Build, Terraform)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                 CAPA 1: FUENTES DE DATOS                        â”‚
â”‚    (PostgreSQL, MySQL, MongoDB, SAP, Salesforce, SurveyMonkey)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 DescripciÃ³n de Capas

#### Capa 1: Fuentes de Datos

Sistemas origen que alimentan la plataforma:

| Fuente | Tipo | Protocolo de ExtracciÃ³n |
|--------|------|------------------------|
| PostgreSQL | RDBMS | CDC (Change Data Capture) / Bulk |
| MySQL | RDBMS | CDC / Bulk |
| MongoDB | NoSQL Document | Change Streams / Bulk |
| SAP | ERP | API / RFC |
| Salesforce | CRM SaaS | REST API |
| SurveyMonkey | Survey SaaS | REST API |

#### Capa 2: GitOps & DataOps

| Componente | Herramienta | FunciÃ³n |
|------------|-------------|---------|
| Control de versiones | GitHub / GitLab | Versionado de cÃ³digo, dbt projects, IaC |
| CI/CD | Cloud Build / GitHub Actions | Testing, validaciÃ³n, despliegue automÃ¡tico |
| Infraestructura como CÃ³digo | Terraform | ProvisiÃ³n de todos los recursos GCP |

**Flujo GitOps:**
```
Developer â†’ PR â†’ Code Review â†’ Merge â†’ CI/CD Pipeline â†’ Deploy
```

#### Capa 3: Plataforma Central (GCP)

| Componente | TecnologÃ­a | JustificaciÃ³n |
|------------|------------|---------------|
| **Ingesta** | Airbyte (en GKE) | Open-source, +300 conectores, extensible |
| **OrquestaciÃ³n** | Cloud Composer (Airflow) | Servicio gestionado, integraciÃ³n nativa GCP |
| **Data Lake** | GCS Buckets | Almacenamiento escalable, formato Parquet/Delta |

#### Capa 4: Dominio Maisons (Arquitectura Medallion)

El dominio **Maisons** es el proyecto GCP principal que contiene todos los datos organizados en la arquitectura Medallion:

```
ğŸ“ Proyecto GCP: maisons-data-platform
â”‚
â”œâ”€â”€ ğŸ¥‰ Dataset: bronze (Raw Data)
â”‚   â”œâ”€â”€ raw_clientes          â† Datos crudos de Salesforce
â”‚   â”œâ”€â”€ raw_productos         â† Datos crudos de SAP
â”‚   â”œâ”€â”€ raw_ventas            â† Datos crudos de PostgreSQL
â”‚   â”œâ”€â”€ raw_surveys           â† Datos crudos de SurveyMonkey
â”‚   â””â”€â”€ raw_[nuevas_fuentes]  â† Extensible
â”‚
â”œâ”€â”€ ğŸ¥ˆ Dataset: silver (Cleaned & Conformed)
â”‚   â”œâ”€â”€ stg_clientes          â† Limpieza, tipado, deduplicaciÃ³n
â”‚   â”œâ”€â”€ stg_productos         â† NormalizaciÃ³n, validaciones
â”‚   â”œâ”€â”€ stg_ventas            â† Joins bÃ¡sicos, filtros
â”‚   â”œâ”€â”€ stg_surveys           â† Parsing de respuestas
â”‚   â””â”€â”€ int_[intermedios]     â† Modelos intermedios compartidos
â”‚
â””â”€â”€ ğŸ¥‡ Datasets Gold (Marts por Entidad)
    â”‚
    â”œâ”€â”€ ğŸ“Š Dataset: gold_clientes
    â”‚   â”œâ”€â”€ dim_clientes          â† DimensiÃ³n cliente
    â”‚   â”œâ”€â”€ mart_clientes_360     â† Vista 360 del cliente
    â”‚   â””â”€â”€ fct_interacciones     â† Hechos de interacciones
    â”‚
    â”œâ”€â”€ ğŸ“Š Dataset: gold_productos
    â”‚   â”œâ”€â”€ dim_productos         â† DimensiÃ³n producto
    â”‚   â”œâ”€â”€ mart_catalogo         â† CatÃ¡logo enriquecido
    â”‚   â””â”€â”€ fct_inventario        â† Hechos de inventario
    â”‚
    â”œâ”€â”€ ğŸ“Š Dataset: gold_ventas
    â”‚   â”œâ”€â”€ fct_transacciones     â† Hechos de ventas
    â”‚   â”œâ”€â”€ agg_ventas_diarias    â† Agregaciones diarias
    â”‚   â””â”€â”€ mart_performance      â† KPIs de ventas
    â”‚
    â””â”€â”€ ğŸ“Š Dataset: gold_[extensible]
        â””â”€â”€ mart_[nuevo]          â† Futuros marts
```

##### Arquitectura Medallion (Bronze â†’ Silver â†’ Gold)

| Capa | Dataset | PropÃ³sito | Transformaciones | Acceso |
|------|---------|-----------|------------------|--------|
| **ğŸ¥‰ Bronze** | `bronze` | Datos crudos, inmutables | Ninguna (1:1 con fuente) | Solo ingesta |
| **ğŸ¥ˆ Silver** | `silver` | Datos limpios, conformados | Tipado, dedup, validaciÃ³n | Equipo Data |
| **ğŸ¥‡ Gold** | `gold_*` | Marts de negocio | Joins, agregaciones, KPIs | BI, ML, APIs |

##### Estructura dbt

```
dbt_project_maisons/
â”œâ”€â”€ dbt_project.yml
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ staging/                    â†’ Dataset: bronze
â”‚   â”‚   â”œâ”€â”€ _staging__sources.yml
â”‚   â”‚   â”œâ”€â”€ stg_clientes.sql
â”‚   â”‚   â”œâ”€â”€ stg_productos.sql
â”‚   â”‚   â”œâ”€â”€ stg_ventas.sql
â”‚   â”‚   â””â”€â”€ stg_surveys.sql
â”‚   â”‚
â”‚   â”œâ”€â”€ intermediate/               â†’ Dataset: silver
â”‚   â”‚   â”œâ”€â”€ int_clientes_enriched.sql
â”‚   â”‚   â”œâ”€â”€ int_productos_inventory.sql
â”‚   â”‚   â””â”€â”€ int_ventas_joined.sql
â”‚   â”‚
â”‚   â””â”€â”€ marts/                      â†’ Datasets: gold_*
â”‚       â”œâ”€â”€ clientes/               â†’ gold_clientes
â”‚       â”‚   â”œâ”€â”€ dim_clientes.sql
â”‚       â”‚   â”œâ”€â”€ mart_clientes_360.sql
â”‚       â”‚   â””â”€â”€ fct_interacciones.sql
â”‚       â”‚
â”‚       â”œâ”€â”€ productos/              â†’ gold_productos
â”‚       â”‚   â”œâ”€â”€ dim_productos.sql
â”‚       â”‚   â”œâ”€â”€ mart_catalogo.sql
â”‚       â”‚   â””â”€â”€ fct_inventario.sql
â”‚       â”‚
â”‚       â””â”€â”€ ventas/                 â†’ gold_ventas
â”‚           â”œâ”€â”€ fct_transacciones.sql
â”‚           â”œâ”€â”€ agg_ventas_diarias.sql
â”‚           â””â”€â”€ mart_performance.sql
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ generic/
â”‚   â””â”€â”€ singular/
â”‚
â””â”€â”€ macros/
```

#### Capa 5: Gobernanza Federada

| Pilar | Componente | FunciÃ³n |
|-------|------------|---------|
| **Control de Acceso** | Cloud IAM | Roles y polÃ­ticas a nivel proyecto/dataset |
| | Column-Level Security | RestricciÃ³n de columnas sensibles (PII) en Gold |
| **CatalogaciÃ³n** | DataHub | CatÃ¡logo central, linaje automÃ¡tico desde dbt |
| **Calidad de Datos** | Great Expectations | Validaciones de schema y datos en Gold |
| | dbt Tests | Tests integrados en cada capa |
| **Observabilidad** | Cloud Monitoring | MÃ©tricas de pipelines, logs centralizados |
| | Cloud Alerting + Slack/PagerDuty | Notificaciones proactivas |

#### Capa 6: Consumo

| Caso de Uso | Herramienta | Datasets Accesibles |
|-------------|-------------|---------------------|
| **BI / Dashboards** | Apache Superset | `gold_*` Ãºnicamente |
| **ML / Predicciones** | Vertex AI | `gold_*` + `silver` (features) |
| **APIs de Datos** | Cloud Run / Cloud Functions | `gold_*` Ãºnicamente |

---

## 4. Decisiones de Arquitectura (ADRs)

### ADR-001: Airbyte sobre Fivetran para Ingesta

**Contexto:** Se requiere una herramienta de EL (Extract-Load) con mÃºltiples conectores.

**DecisiÃ³n:** Airbyte desplegado en GKE.

**JustificaciÃ³n:**
- âœ… Open-source (requisito del cliente)
- âœ… +300 conectores pre-construidos
- âœ… Extensible mediante Connector Builder
- âœ… Desplegable en Kubernetes (control total)
- âŒ Fivetran: SaaS propietario, costos por volumen

**Consecuencias:**
- Mayor control y personalizaciÃ³n
- Requiere gestiÃ³n del cluster GKE
- Posibilidad de contribuir conectores custom

---

### ADR-002: Cloud Composer sobre Airflow self-managed

**Contexto:** Se necesita orquestaciÃ³n de pipelines de datos.

**DecisiÃ³n:** Cloud Composer (Airflow gestionado).

**JustificaciÃ³n:**
- âœ… Airflow es open-source (satisface requisito)
- âœ… Servicio gestionado reduce overhead operacional
- âœ… IntegraciÃ³n nativa con GCS, BigQuery, Dataflow
- âœ… Auto-scaling, alta disponibilidad incluida

**Consecuencias:**
- Menor control que self-managed
- Costo fijo del servicio gestionado
- Actualizaciones gestionadas por Google

---

### ADR-003: Arquitectura Medallion (Bronze/Silver/Gold)

**Contexto:** Se necesita una estructura de datos que permita trazabilidad, reprocesamiento y separaciÃ³n de concerns.

**DecisiÃ³n:** Implementar arquitectura Medallion con datasets separados por capa.

**JustificaciÃ³n:**
- âœ… **Bronze:** Preserva datos crudos para auditorÃ­a y reprocesamiento
- âœ… **Silver:** Centraliza lÃ³gica de limpieza, evita duplicaciÃ³n
- âœ… **Gold:** Marts optimizados para consumo, separados por entidad
- âœ… Control de acceso granular por capa
- âœ… PatrÃ³n probado en la industria (Databricks, Delta Lake)

**Consecuencias:**
- Mayor almacenamiento (datos en mÃºltiples capas)
- Latencia adicional por transformaciones en capas
- Claridad en ownership y responsabilidades

---

### ADR-004: Datasets Gold Separados por Entidad

**Contexto:** Los marts de negocio deben servir a diferentes equipos y casos de uso.

**DecisiÃ³n:** Crear un dataset `gold_*` por cada entidad de negocio (clientes, productos, ventas, etc.).

**JustificaciÃ³n:**
- âœ… **Control de acceso granular:** Equipo de ventas solo accede a `gold_ventas`
- âœ… **Escalabilidad:** Nuevas entidades = nuevos datasets sin afectar existentes
- âœ… **Ownership claro:** Cada dataset tiene un owner definido
- âœ… **Costos controlados:** Queries solo escanean datasets necesarios

**Consecuencias:**
- MÃ¡s datasets que administrar
- Requiere convenciÃ³n de nombres estricta
- Cross-domain queries requieren permisos explÃ­citos

---

### ADR-005: DataHub sobre Google Data Catalog

**Contexto:** Se requiere catalogaciÃ³n de datos con linaje.

**DecisiÃ³n:** DataHub open-source.

**JustificaciÃ³n:**
- âœ… Open-source (requisito del cliente)
- âœ… Linaje automÃ¡tico desde dbt (manifest.json)
- âœ… API extensible para integraciones custom
- âœ… UI moderna para discovery
- âŒ Data Catalog: Menos features, no open-source

**Consecuencias:**
- Requiere despliegue y mantenimiento
- Comunidad activa (LinkedIn backed)

---

### ADR-006: Apache Superset sobre Looker/Tableau

**Contexto:** Se necesitan dashboards de BI self-service.

**DecisiÃ³n:** Apache Superset.

**JustificaciÃ³n:**
- âœ… Open-source (requisito del cliente)
- âœ… SQL Lab para exploraciÃ³n ad-hoc
- âœ… Conector nativo BigQuery
- âœ… Role-based access control
- âŒ Looker: Propietario, costo elevado

**Consecuencias:**
- Menor polish que herramientas enterprise
- Requiere capacitaciÃ³n de usuarios

---

## 5. Data Mesh: Principios Aplicados

### 5.1 Los 4 Principios de Data Mesh

| Principio | ImplementaciÃ³n |
|-----------|----------------|
| **Domain Ownership** | Dominio Maisons es owner del proyecto GCP completo. Cada dataset Gold tiene un equipo responsable. |
| **Data as a Product** | Los `mart_*` en Gold son productos de datos con SLAs, documentaciÃ³n en dbt, y ownership claro |
| **Self-serve Platform** | Plataforma central (Airbyte, Composer, GCS) provee ingesta y orquestaciÃ³n como servicio |
| **Federated Governance** | PolÃ­ticas centrales (IAM, calidad) aplicadas consistentemente en todas las capas |

### 5.2 Estructura de un Data Product (Gold)

Cada mart en Gold se expone como producto de datos con:

```yaml
# Ejemplo: Data Product "mart_clientes_360"
name: mart_clientes_360
domain: maisons
dataset: gold_clientes
owner: equipo-clientes@empresa.com
description: Vista unificada del cliente con todas sus interacciones
sla:
  freshness: "< 4 horas"
  availability: "99.9%"
schema:
  - cliente_id (PK)
  - nombre
  - email (PII - restricted)
  - ltv_score
  - segmento
  - ultima_compra_fecha
  - total_compras
quality_checks:
  - not_null: [cliente_id, nombre]
  - unique: [cliente_id]
  - accepted_values: [segmento, ['premium', 'standard', 'basic']]
  - relationships: [cliente_id â†’ dim_clientes.cliente_id]
```

---

## 6. Seguridad y Gobernanza

### 6.1 Modelo de Acceso (IAM) por Capa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Proyecto GCP: maisons-data-platform                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Dataset: bronze                                                â”‚
â”‚  â””â”€â”€ Acceso: Solo Service Account de Airbyte (escritura)        â”‚
â”‚              Solo equipo Data Engineering (lectura)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Dataset: silver                                                â”‚
â”‚  â””â”€â”€ Acceso: Equipo Data Engineering (lectura/escritura)        â”‚
â”‚              Data Scientists (lectura para features)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Datasets: gold_*                                               â”‚
â”‚  â”œâ”€â”€ gold_clientes â†’ Equipo Clientes + Analistas BI             â”‚
â”‚  â”œâ”€â”€ gold_productos â†’ Equipo Productos + Analistas BI           â”‚
â”‚  â”œâ”€â”€ gold_ventas â†’ Equipo Ventas + Analistas BI                 â”‚
â”‚  â””â”€â”€ Column-Level Security en columnas PII                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 ClasificaciÃ³n de Datos por Capa

| Capa | ClasificaciÃ³n | Ejemplos | Acceso |
|------|---------------|----------|--------|
| **Bronze** | Interno | Datos crudos de todas las fuentes | Solo ingesta y data eng |
| **Silver** | Interno | Datos limpios y conformados | Data team |
| **Gold** | Variable | Marts de negocio | Por dataset y columna |

### 6.3 Column-Level Security (Solo en Gold)

```sql
-- Crear taxonomy para PII
CREATE SCHEMA IF NOT EXISTS `maisons-data-platform.taxonomy`;

-- Crear policy tag
CREATE POLICY TAG `maisons-data-platform.taxonomy.pii`
  DESCRIPTION 'InformaciÃ³n Personal Identificable';

-- Aplicar a columnas sensibles en gold_clientes
ALTER TABLE `gold_clientes.mart_clientes_360`
ALTER COLUMN email SET POLICY TAG `maisons-data-platform.taxonomy.pii`;

ALTER TABLE `gold_clientes.dim_clientes`
ALTER COLUMN telefono SET POLICY TAG `maisons-data-platform.taxonomy.pii`;

-- Solo usuarios con rol especÃ­fico pueden ver PII
GRANT `roles/datacatalog.fineGrainedReader`
ON POLICY TAG `maisons-data-platform.taxonomy.pii`
TO 'grupo-acceso-pii@empresa.com';
```

---

## 7. Calidad de Datos por Capa

### 7.1 Estrategia de Testing

| Capa | Herramienta | Tipos de Tests | Ejemplo |
|------|-------------|----------------|---------|
| **Bronze** | dbt tests | Schema, freshness | `source_freshness`, tipos correctos |
| **Silver** | dbt tests | Uniqueness, not null, relationships | PK unique, FK vÃ¡lidas |
| **Gold** | dbt + Great Expectations | Reglas de negocio, distribuciones | `ltv_score BETWEEN 0 AND 100` |

### 7.2 Ejemplos de Tests dbt

```yaml
# models/staging/_staging__sources.yml
sources:
  - name: bronze
    database: maisons-data-platform
    schema: bronze
    freshness:
      warn_after: {count: 12, period: hour}
      error_after: {count: 24, period: hour}
    tables:
      - name: raw_clientes
        columns:
          - name: id
            tests:
              - not_null
              - unique

# models/marts/clientes/_clientes__models.yml
models:
  - name: mart_clientes_360
    description: "Vista 360 del cliente"
    columns:
      - name: cliente_id
        tests:
          - not_null
          - unique
      - name: segmento
        tests:
          - accepted_values:
              values: ['premium', 'standard', 'basic']
      - name: ltv_score
        tests:
          - dbt_utils.accepted_range:
              min_value: 0
              max_value: 100
```

---

## 8. Observabilidad y Monitoreo

### 8.1 MÃ©tricas Clave por Capa

| Capa | MÃ©trica | Alerta |
|------|---------|--------|
| **Ingesta** | Registros cargados en Bronze/hora | < umbral esperado |
| **Ingesta** | Latencia de replicaciÃ³n | > 1 hora |
| **Bronze â†’ Silver** | DuraciÃ³n de jobs dbt staging | > 2x promedio |
| **Silver â†’ Gold** | DuraciÃ³n de jobs dbt marts | > 2x promedio |
| **Calidad** | Tests fallidos (cualquier capa) | Cualquier fallo |
| **Consumo** | Queries lentas en Gold | > 60 segundos |

### 8.2 Stack de Observabilidad

```
Airbyte/Airflow â†’ Cloud Monitoring â†’ Cloud Alerting â†’ Slack/PagerDuty
       â†“
   Cloud Logging â†’ Log-based Metrics â†’ Dashboards
       â†“
   DataHub â†’ Linaje visual â†’ Impact Analysis
```

---

## 9. Plan de Extensibilidad

### 9.1 Agregar Nueva Entidad en Gold

1. **dbt:** Crear carpeta `models/marts/[nueva_entidad]/`
2. **Terraform:** Crear dataset `gold_[nueva_entidad]`
3. **IAM:** Definir roles y permisos para el nuevo dataset
4. **DataHub:** Se actualiza automÃ¡ticamente desde dbt manifest
5. **Tests:** Agregar tests de calidad especÃ­ficos

**Tiempo estimado:** 1-2 dÃ­as

### 9.2 Agregar Nueva Fuente de Datos

1. **Airbyte:** Configurar conector
2. **GCS:** Se usa bucket existente (particionado por fuente)
3. **dbt Bronze:** Crear modelo `stg_[nueva_fuente].sql`
4. **dbt Silver:** Agregar a modelos intermedios si aplica
5. **Tests:** Agregar freshness y schema tests

**Tiempo estimado:** 1-2 dÃ­as para conector existente

### 9.3 Agregar Nuevo Proyecto (Multi-dominio futuro)

Si en el futuro se requieren dominios adicionales fuera de Maisons:

1. **Terraform:** Crear nuevo proyecto GCP
2. **Replicar:** Estructura Bronze/Silver/Gold
3. **Cross-project:** Configurar authorized views si se requiere compartir datos
4. **DataHub:** Registrar nuevo dominio

**Tiempo estimado:** 1-2 semanas

---

## 10. EstimaciÃ³n de Costos (Referencial)

| Componente | Servicio GCP | Costo Mensual Estimado |
|------------|--------------|------------------------|
| Ingesta | GKE (Airbyte) | $200 - $500 |
| OrquestaciÃ³n | Cloud Composer | $300 - $800 |
| Almacenamiento Bronze | BigQuery Storage | $50 - $150 |
| Almacenamiento Silver | BigQuery Storage | $30 - $100 |
| Almacenamiento Gold | BigQuery Storage | $20 - $80 |
| Procesamiento | BigQuery Compute | $200 - $1,000 |
| Data Lake | GCS | $20 - $50 |
| ML | Vertex AI | $100 - $500 |
| Monitoreo | Cloud Monitoring | $50 - $100 |
| **Total Estimado** | | **$970 - $3,280/mes** |

*Nota: Costos varÃ­an segÃºn volumen de datos y frecuencia de procesamiento.*

---

## 11. Riesgos y Mitigaciones

| Riesgo | Probabilidad | Impacto | MitigaciÃ³n |
|--------|--------------|---------|------------|
| Complejidad de Airbyte self-managed | Media | Alto | Runbooks, capacitaciÃ³n, considerar Airbyte Cloud |
| Datos duplicados entre capas | Media | Medio | Lifecycle policies, partitioning por fecha |
| Costos BigQuery no controlados | Media | Alto | Quotas, slot reservations, monitoreo |
| Calidad de datos en fuentes | Alta | Alto | Validaciones en Bronze, alertas tempranas |
| Latencia Bronzeâ†’Gold elevada | Baja | Medio | Incremental models, paralelizaciÃ³n |

---

## 12. PrÃ³ximos Pasos

1. **Fase 1 (Semanas 1-4):** Infraestructura base con Terraform
   - Proyecto GCP Maisons
   - Datasets bronze, silver, gold_clientes
   - Cloud Composer, GKE para Airbyte

2. **Fase 2 (Semanas 5-8):** Ingesta de primeras fuentes
   - Configurar Airbyte (PostgreSQL, Salesforce)
   - Modelos dbt Bronze y Silver

3. **Fase 3 (Semanas 9-12):** Primer dataset Gold completo
   - `gold_clientes` con mart_clientes_360
   - Tests de calidad, documentaciÃ³n
   - ConexiÃ³n con Superset

4. **Fase 4 (Semanas 13-16):** Datasets Gold adicionales
   - `gold_productos`, `gold_ventas`
   - DataHub para catalogaciÃ³n

5. **Fase 5 (Semanas 17-20):** ML y optimizaciÃ³n
   - Vertex AI Feature Store
   - OptimizaciÃ³n de costos y performance

---

## Anexo A: TecnologÃ­as Utilizadas

| CategorÃ­a | TecnologÃ­a | Licencia | VersiÃ³n Recomendada |
|-----------|------------|----------|---------------------|
| Ingesta | Airbyte | Open Source (MIT) | 0.50+ |
| OrquestaciÃ³n | Apache Airflow | Apache 2.0 | 2.7+ |
| TransformaciÃ³n | dbt Core | Apache 2.0 | 1.7+ |
| Data Warehouse | BigQuery | Propietario (GCP) | N/A |
| CatÃ¡logo | DataHub | Apache 2.0 | 0.12+ |
| Calidad | Great Expectations | Apache 2.0 | 0.18+ |
| BI | Apache Superset | Apache 2.0 | 3.0+ |
| ML Platform | Vertex AI | Propietario (GCP) | N/A |
| IaC | Terraform | MPL 2.0 | 1.6+ |

---

## Anexo B: Convenciones de Nomenclatura

### Datasets BigQuery

| Capa | PatrÃ³n | Ejemplo |
|------|--------|---------|
| Bronze | `bronze` | `bronze` |
| Silver | `silver` | `silver` |
| Gold | `gold_[entidad]` | `gold_clientes`, `gold_productos` |

### Tablas/Vistas

| Capa | Prefijo | Ejemplo |
|------|---------|---------|
| Bronze | `raw_` | `raw_clientes`, `raw_ventas` |
| Silver | `stg_` / `int_` | `stg_clientes`, `int_ventas_enriched` |
| Gold | `dim_` / `fct_` / `mart_` / `agg_` | `dim_clientes`, `fct_ventas`, `mart_clientes_360` |

---

## Anexo C: Referencias

- [Data Mesh Principles - Zhamak Dehghani](https://martinfowler.com/articles/data-mesh-principles.html)
- [Medallion Architecture - Databricks](https://www.databricks.com/glossary/medallion-architecture)
- [Airbyte Documentation](https://docs.airbyte.com/)
- [dbt Best Practices](https://docs.getdbt.com/guides/best-practices)
- [DataHub Architecture](https://datahubproject.io/docs/architecture/architecture)
- [BigQuery Best Practices](https://cloud.google.com/bigquery/docs/best-practices-performance-overview)
